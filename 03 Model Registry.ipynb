{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "What is a Model Registry?\n",
    "A machine learning model registry is a centralized tracking system that stores lineage, versioning, and related metadata \n",
    "for published machine learning models.\n",
    "\n",
    "A registry may capture governance data required for auditing purposes, such as who trained and published a model, which \n",
    "datasets were used for training, the values of metrics measuring predictive performance, and when the model was deployed to \n",
    "production.\n",
    "\n",
    "Model Registry is a service that manages model artifacts and tracks which models are deployed in production.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Why Model Registry?\n",
    "    We train the model once and serialize it into a file called model.pkl. Specifically we use pickling in the Python world to \n",
    "    do the serialization.\n",
    "    After that, we store the file in S3, Amazonâ€™s cloud storage system. Then we build an API service that reads the file from \n",
    "    S3, deserializes the model, and starts to make predictions.\n",
    "    \n",
    "    This design pattern is actually common in the industry, but also has a few main drawbacks.\n",
    "    \n",
    "    - The model might get stale over time, especially if the data distribution changes over time, which is often true for the \n",
    "      housing market.\n",
    "    - Because the model is only trained once, the training code will not be well maintained, which makes it harder to reproduce\n",
    "      later.\n",
    "\n",
    "With that in mind, we would like to move to a world where we train models regularly. It is easy to set up a cron job to do \n",
    "that. However,it is also crucial to track the history of different runs of model training. The things to track include training \n",
    "dates, features, hyperparameters, and performance metrics. With those, we can compare with historical benchmarks and understand \n",
    "how good a new model is.   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Model Registry\n",
    "This is where Model Registry comes in. It is a service that helps us manage multiple model artifacts.\n",
    "Users interact with the service through a gRPC API to log and retrieve their models. The service has the following core.\n",
    "\n",
    "Concepts:\n",
    "    - TrainingInfo: All the information related to the training and backtesting of one model artifact. \n",
    "          It contains information such as model type, artifact S3 path, features, and creation time.\n",
    "    - Parameter: A key/value pair representing a model training parameter, such as the city for which the model was trained.\n",
    "    - Metric: A key/value pair representing a model evaluation metric, such as MSE (mean squared error)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Model Registry  tool : ML Flow"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
