{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''''\n",
    "IoT Device -->IoT Hub --> Azure Stream Analytic Job(Input and OutPut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "1. Create 'IOT Hub'\n",
    "    - IOTHub1243\n",
    "    \n",
    "2. Go to Home Select created Iot Hub 'IOTHub1243'\n",
    "\n",
    "3. Click on 'Devices' from 'Device Management' from the left pane\n",
    "\n",
    "4. click on 'Add Device'\n",
    "\t- Provide the 'Device ID' as Iotdevice_1243\n",
    "\t- Click on 'Save'\n",
    "\n",
    "5. Click on newly added device (Iotdevice_1243)\n",
    "\t- Here you will get see the details\n",
    "\t\t1. Device ID\n",
    "\t\t2. Primary Key\n",
    "\t\t3. Secondary Key\n",
    "\t\t4. Primary Connection String\n",
    "\t\t5. Secondary Connection String\n",
    "\n",
    "6. Got 'Raspberry Pi Azure IoT Online Simulator' \n",
    "\t- https://azure-samples.github.io/raspberry-pi-web-simulator/\n",
    "\n",
    "7. Copy the Primary connection string from Iotdevice_1243 and paste on the Simulator\n",
    "\t- connectionString = 'HostName=IOT1243.azure-devices.net;DeviceId=Iotdevic43;Shay=1E92jmg7k/PtiqmcFZfv/UDPz7VyU='\n",
    "\n",
    "8. Click on Run make sure Led on the web simulator is blinking\n",
    "\n",
    "9. Go back to Azure Home Search for 'Stream Analytic Job' and click on Create\n",
    "\t- Jobname = RSSAJ1243\n",
    "\t- Select the Default 'Streaming Units'\n",
    "\t- Click on Create\n",
    "\n",
    "10. Go to 'Stream Analytics Job' abd select newly created one 'RSSAJ1243'\n",
    "\n",
    "11. In the 'Job Topology' on the left hand pane you could see\n",
    "\t- Inputs\n",
    "\t- Functions\n",
    "\t- Query\n",
    "\t- outputs\n",
    "\n",
    "12. Click on 'Inputs' from 'Job Topology'\n",
    "\t- Provide Input Alias Name\n",
    "\n",
    "13. Click on 'Outputs' and select Data Lake Storage gen1\n",
    "\n",
    "14. In 'Stream Analytics Job' you can write Query to read data from input and save it to output\n",
    "\n",
    "15. Select 'Stream Analytics Job' and Click on 'Start'\n",
    "\n",
    "16. Incase you if want Modify the query written on the 'Stream Analytics Job' make sure we stop the job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Input Type Supported by 'Azure Stream Analytics'\n",
    "    1. Streaming Input\n",
    "        1. Blob Storage / ADLS Gen2\n",
    "        2. Event Hub\n",
    "        3. IoT Hub\n",
    "        \n",
    "    2. Reference Input\n",
    "        1. Blob Storage / ADLS Gen2\n",
    "        2. SQL Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Output  Type Supported on the 'Azure Stream Analytics'\n",
    "\n",
    "    1. Azure Function\n",
    "    2. Azure PostgreSQL\n",
    "    3. Azure Synapse Analytics\n",
    "    4. Blob Storage\n",
    "    5. Cosmo DB\n",
    "    6. Data Lake Storage\n",
    "    7. Event Hub\n",
    "    8. Power BI\n",
    "    9. Service Bus Queue\n",
    "    10. Service Bus topic\n",
    "    11. SQL Database\n",
    "    12. Table Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
