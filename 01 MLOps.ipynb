{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "ML Ops:\n",
    "    - ML Ops is a set of practices that combines Machine Learning, DevOps and Data Engineering, which aims to deploy and \n",
    "      maintain ML systems in production reliably and efficiently.\n",
    "    - The term MLOps refers to a set of techniques and practises for data scientists to collaborate operations professionals.\n",
    "    - MLOps aims to manage deployment of machine learning and deep learning models in large-scale production environments.\n",
    "    \n",
    "The overall steps for deploying an ML/DL model in production are:\n",
    "    - Data extraction\n",
    "    - Data analysis\n",
    "    - Data preparation\n",
    "    - Model training\n",
    "    - Model evaluation\n",
    "    - Model serving\n",
    "    - Model monitoring\n",
    "    \n",
    "ML Pipelines:\n",
    "\n",
    "    - One of the core concepts of Data Engineering is the data pipeline.\n",
    "    - A data pipeline is a series of transformations that are applied to data between its source and a destination.\n",
    "    - There are many specialized tools that help create, manage and run these pipelines.\n",
    "    - Data pipelines can also be called ETL (extract, transform and load) pipelines.\n",
    "\n",
    "Differences between MLOps and DevOps\n",
    "        - In MLOps, in addition to testing the code you also need to ensure data quality is maintained across the machine \n",
    "          learning project life cycle\n",
    "        - In MLOps, you may not necessarily be deploying just a model artifact.\n",
    "        \n",
    "Deployment of a machine learning system can require a machine learning pipeline that involves data extraction, data processing, \n",
    "feature engineering, model training, model registry and model deployment.\n",
    "\n",
    "In MLOps there is a third concept that does not exist in DevOps which is Continuous Training (CT). \n",
    "\n",
    "This step is all about automatically identifying scenarios/events that requires a model to be re-trained and re-deployed into \n",
    "production due to a performance degradation in the currently deployed machine learning model/system.\n",
    "\n",
    "Platforms and tools to assist with MLOps\n",
    "    - mlflow : This is a open source platform that aids and assists in the model tracking, model registry and model deployment \n",
    "      steps.\n",
    "    - version control system such as:\n",
    "        - github\n",
    "        - gitlab\n",
    "        - Azure DevOps\n",
    "    Cloud service to conduct experiments and deploy the machine learning pipeline\n",
    "        - AWS SageMaker\n",
    "        - Azure Machine Learning\n",
    "        \n",
    "Machine learning model deployment can be categorised into 3 broad categories:\n",
    "    - Real-time inference:\n",
    "        - Typically it involves hosting a machine learning model as a endpoint on a web server.\n",
    "          Applications can then provide data via https and receive back,in a short period of time, the predictions of the model.\n",
    "    - Batch inference:\n",
    "        - On a regular basis (triggered by time or events such as data landing into a data lake/data store) resources are spun \n",
    "          up and a machine learning model is deployed to predict on the new data that is now available in the data lake/data \n",
    "          store.\n",
    "    - Model deployment onto edge:\n",
    "        - Instead of requiring input data to be passed to a back end the model prediction is computed on edge devices. Think \n",
    "          IoT and web applications.\n",
    "          \n",
    "Some of the tools used for Deployment of Machine Learnign Models\n",
    "    - MlFlow\n",
    "    - TFX\n",
    "    - Kubeflow\n",
    "    \n",
    "Model Formats:\n",
    "    - Pickle \n",
    "    - ONNX :  Open Neural Network Exchange format\n",
    "    - PMML : Predictive model markup language\n",
    "    - POJO and MOJO are H2O.ai’s export format\n",
    "    \n",
    "Machine Learning Inference? \n",
    "    - Machine learning (ML) inference is the process of running live data points into a machine learning algorithm (or “ML \n",
    "      model”) to calculate an output such as a \tsingle numerical score.\n",
    "      \n",
    "    - This process is also referred to as “operationalizing an ML model” or “putting an ML model into production.” When an ML \n",
    "      model is running in production, it is often then described as artificial intelligence (AI) since it is performing \n",
    "      functions similar to human thinking and analysis.\n",
    "      \n",
    "When deciding which method to deploy machine learning model(s) into production several factors need to be taken into \n",
    "consideration.\n",
    "    - Latency : How quickly does an application/user require the results of the model prediction?\n",
    "    - Data Privacy: Is there any issues/concerns of sending data to a back end?\n",
    "    - Network connectivity: Some deployment options requires access to the internet/network. If the environment in which the \n",
    "      model needs to be deployed has limited or no internet/network connectivity, the options are limited.\n",
    "    - Cost: tain deployment options will be more costly then others. Think having a server online 24/7 to serve predictions. \n",
    "      What will be the cost to operate and maintain this server?\n",
    "      \n",
    "Difference Between DevOps and MLOps\n",
    "    - Unlike DevOps, MLOps is much more experimental in nature. Data scientists try different features, parameters, models. In \n",
    "      all these iterations, they must manage the code base and create reproducible results.\n",
    "      \n",
    "Performance degradation of the system due to changing data profiles: ML and DL systems are impacted by changing data profiles. \n",
    "This is not the case in a traditional IT system. Hence, the model has to be refreshed even if it ‘works’ currently – leading to \n",
    "more iterations in the pipeline.\n",
    "\n",
    "Model monitoring: Models in production need to be monitored. Similarly, the summary statistics of data that built the model \n",
    "needs to be monitored so that we can refresh models when needed.\n",
    "\n",
    "Automation of steps before model building: There are many steps before a model is built that may need to be automated.\n",
    "\n",
    "Team composition: The team needed to build and deploy models in production may not always comprise of software engineers. \n",
    "For example, the members working with exploratory data analysis maybe business experts as opposed to software engineers.\n",
    "\n",
    "Testing: Testing an ML system involves model validation, model training etc – in addition to the software tests such as \n",
    "unit testing and integration testing.\n",
    "\n",
    "Continuous integration (CI) for MLOps also involves validating the data and the schema in addition to testing code.\n",
    "\n",
    "Continuous deployment(CD) validating the performance of models in production – including the ability to deploy new models and \n",
    "rollback changes from a model.\n",
    "\n",
    "We need a new term –Continuous testing (CT) to retrain and serve models.\n",
    "\n",
    "With DevOps, code version control is utilized to ensure clear documentation regarding any changes or adjustments made to the \n",
    "software being developed. With machine learning, however, the code isn't the only changing input. Data is the other critical \n",
    "input that'll need to be managed, as will parameters, metadata, logs, and finally, the model.\n",
    "\n",
    "“MLOps = Machine Learning (Data Scientists and Data Engineers) + IT Operations (DevOps, CI/CD and Infra folks)”\n",
    "\n",
    "Things to consider when deploying a model\n",
    "    - Scaling your API\n",
    "    - Containerizing your API environment\n",
    "    - Documenting your API\n",
    "    - Retraining your model to avoid model drift\n",
    "    - Logging your API and model\n",
    "    - Cloud or on-premise?\n",
    "    \n",
    "\n",
    "The MLOps technology stack should include tooling for the following tasks:\n",
    "    - data engineering,\n",
    "    - version control of data, ML models and code,\n",
    "    - coninuous integration and continuous delivery pipelines,\n",
    "    - automating deployments and experiments,\n",
    "    - model performance assessment, and\n",
    "    - model monitioring in production.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Major Phases MLOps\n",
    "\n",
    "1. Framing ML problems from business objectives\n",
    "    - Machine learning systems development typically starts with a business goal or objective. \n",
    "    - These objectives often have certain performance measures,Technical requirements, budget for the project, and KPIs\n",
    "       (Key Performance Indicators)\n",
    "       \n",
    "2. Architect ML and data solutions for the problem\n",
    "    - The next step is to start searching for appropriate input data and the kind of models that are to be tried for that kind \n",
    "      of data.\n",
    "    - Searching for data is one of the most strenuous tasks. \n",
    "        - You need to look for any available relevant dataset,\n",
    "        - Check the credibility of the data and its source.\n",
    "        - Is the data source compliant with regulations like GDPR?: General Data Protection Regulation\n",
    "        - How to make the dataset accessible?\n",
    "        - What is the type of source — static(files) or real-time streaming(sensors)?\n",
    "        - How many sources are to be used?\n",
    "        - How to build a data pipeline that can drive both training and optimization once the model is deployed in the \n",
    "          production environment\n",
    "        - What all cloud services are to be used?\n",
    "\n",
    "3. Data preparation and processing — part of data engineering.\n",
    "    - Data preparation includes tasks like feature engineering, cleaning(formatting, checking for outliers, imputations, \n",
    "      rebalancing, etc), and then selecting the set of features that contribute to the output of the underlying problem.\n",
    "    - Creating data pipelines\n",
    "    \n",
    "\n",
    "4. Model training and experimentation — data science\n",
    "    - As soon as your data is prepared, you move on to the next step of training your ML model. Now, the initial phase of \n",
    "      training is iterative with a bunch of different types of models.\n",
    "    - You will be narrowing down to the best solution using several quantitative measures like accuracy, precision, recall, \n",
    "      etc and you can also use qualitative analysis of the model which accounts for the mathematics that drives that model, \n",
    "      or simply sput the explainability of the model\n",
    "      \n",
    "5. Building and automating ML pipelines\n",
    "    - ML pipelines are to be built keeping in mind the following tasks:\n",
    "        - Identify system requirements — parameters, compute needs, triggers.\n",
    "        - Choose an appropriate cloud architecture — hybrid or multi-cloud.\n",
    "        - Construct training and testing pipelines.\n",
    "        - Track and audit the pipeline runs.\n",
    "        - Perform data validation.\n",
    "        \n",
    "6. Deploying models to the production system\n",
    "    - There are mainly two ways of deploying an ML model:\n",
    "        - Static deployment or embedded model is where the model is packaged into installable application software and then \n",
    "          deployed. \n",
    "          For example, an application that offers batch-scoring of requests.\n",
    "\n",
    "        - Dynamic deployment — where the model is deployed using a web framework like FastAPI or Flask and is offered as an API \n",
    "          endpoint that responds to user requests.\n",
    "\n",
    "        - Within dynamic deployment, you can use different methods:\n",
    "            - deploying on a server( a virtual machine)\n",
    "            - deploying in a container\n",
    "            - serverless deployment\n",
    "            - model streaming — instead of REST APIs, all of the models and application code are registered on a \n",
    "                      stream processing engine like Apache Spark, Apache Storm, and Apache Flink.\n",
    "\n",
    "        Following are the considerations:\n",
    "            - Ensuring proper documentation and testing scores are met.\n",
    "            - Revalidating the model accuracy.\n",
    "            - Performing explainability checks.\n",
    "            - Ensuring all governance requirements have been met.\n",
    "            - Checking the quality of any data artifacts\n",
    "            - Load testing — compute resource usage.\n",
    "            \n",
    "            \n",
    "7. Monitor, optimize and maintain models\n",
    "    - An organization needs to keep an eye on the performance of the models in production but ensuring good and fair governance.\n",
    "    - Governance here means placing in control measures to ensure that the models deliver on their responsibilities to all the \n",
    "      stakeholders, employees, and users that are affected by them\n",
    "          \n",
    "    As part of this phase, we need data scientists and DevOps engineers to maintain the whole system in production by \n",
    "    performing the following tasks:\n",
    "        - Keeping track of performance degradation and business quality of model predictions\n",
    "        - Setting up logging strategies and establishing continuous evaluation metrics\n",
    "        - Troubleshooting system failures and introduction of biases.\n",
    "        - Tuning the model performance in both training and serving pipelines deployed in production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "ML Pipelines\n",
    "\n",
    "A machine learning pipeline is a way to modularize or codify and automate the workflow it takes to produce a machine learning \n",
    "model.\n",
    "\n",
    "A machine learning pipeline is used to help automate machine learning workflows. \n",
    "\n",
    "ML Pipe line consists of below the steps\n",
    "    1. Data Ingestion\n",
    "    2. Model Training\n",
    "    3. Model Testing\n",
    "    4. Model packaging\n",
    "    5. Model Registering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "ML Model Inference\n",
    "\n",
    "Predicting or making a decision using an ML model is called ML model Inference.\n",
    "\n",
    "Deploying ML Model on different Deployment targets to Facilitate ML Inference.\n",
    "\n",
    "    1. Virtual Machines or an on-premises server\n",
    "    2. Containers\n",
    "    3. Serverless\n",
    "    4. Model Streaming "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Artifcats and MetaData\n",
    "\n",
    "    - The model consists of artifacts, files that are generated during training.\n",
    "    - Artifacts : model architecture and model weights\n",
    "    - metadata : Data snapshot, version used for trainig,testing "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
